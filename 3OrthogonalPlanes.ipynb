{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1rhfQfyCndjmLdXRT-Rwq8XBXJfWCR3lX",
      "authorship_tag": "ABX9TyNGJ+G3ahNNTOLyJp5Kro7C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Basantallam/MachineLearning-Segmentation/blob/main/3OrthogonalPlanes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHH-o2vefbvz"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import nibabel\r\n",
        "from skimage.transform import resize\r\n",
        "\r\n",
        "data_path = '//content//drive//MyDrive'\r\n",
        "\r\n",
        "\r\n",
        "def create_train_data():\r\n",
        "    print('-'*30)\r\n",
        "    print('Creating training data...')\r\n",
        "    print('-'*30)\r\n",
        "    #listing names of all training data into an array of strings\r\n",
        "    #1st array is for input and the 2nd for labels (masks)\r\n",
        "    train_data_path = os.path.join(data_path, 'train//train')\r\n",
        "    training_images = os.listdir(train_data_path)\r\n",
        "\r\n",
        "    train_mask_data_path = os.path.join(data_path, 'train//train_masks')\r\n",
        "    training_masks = os.listdir(train_mask_data_path)\r\n",
        "\r\n",
        "    #sorting file names alphabetically so they are correctly ordered  \r\n",
        "    list.sort(training_images)\r\n",
        "    list.sort(training_masks)\r\n",
        "\r\n",
        "    #since we are doing 2.5D we will only use specific 2D images from the 3D image\r\n",
        "    #the chosen 2D images will be appended to the following two arrays:\r\n",
        "\r\n",
        "    #training images\r\n",
        "    imgs_train = [] \r\n",
        "    #training masks \r\n",
        "    masks_train = [] \r\n",
        "\r\n",
        "    #looping over names of 3D images and extracting 2D images from them\r\n",
        "    for i in range(0,len(training_images)):\r\n",
        "        # every patient has 4 mri modalities with only 1 mask \r\n",
        "        # so \"i\" is divided by 4 in training_masks[i//4] so the same mask \r\n",
        "        # is used for with its 4 corresponding mri scans\r\n",
        "        # we load 3D training masks\r\n",
        "        training_mask = nibabel.load(os.path.join(train_mask_data_path,training_masks[i//4]))\r\n",
        "        #we load 3D training image\r\n",
        "        training_image = nibabel.load(os.path.join(train_data_path, training_images[i])) \r\n",
        "        \r\n",
        "        #3D image is converted to a 3D numpy array\r\n",
        "        #k is the index you  take the 2D image at.\r\n",
        "        #In this approach we took 3 consecutive 2D images from the center of the 3Dimage in 3 orthogonal planes\r\n",
        "        for k in range((training_mask.shape[2]//2)-1,(training_mask.shape[2]//2)+1):\r\n",
        "            #axial cuts are made along the z axis\r\n",
        "            print(training_mask.get_fdata().shape)\r\n",
        "\r\n",
        "            mask_2d = np.array(training_mask.get_fdata()[::, ::, k]) \r\n",
        "            image_2d = np.array(training_image.get_fdata()[::, ::, k])\r\n",
        "            \r\n",
        "            image_2d_resized = resize(image_2d, (128,128), preserve_range=True)\r\n",
        "            mask_2d_resized = resize(mask_2d, (128,128), preserve_range=True)\r\n",
        "           \r\n",
        "            print(\"k=\"+str(k))\r\n",
        "           #array of chosen 2D images of all patients appended together \r\n",
        "           #(Array of 2D arrays)\r\n",
        "            masks_train.append(mask_2d_resized)\r\n",
        "            imgs_train.append(image_2d_resized)\r\n",
        "\r\n",
        "        for k in range((training_mask.shape[1]//2)-1,(training_mask.shape[1]//2)+1):\r\n",
        "            #axial cuts are made along the y axis\r\n",
        "            mask_2d = np.array(training_mask.get_fdata()[::, k, ::]) \r\n",
        "            image_2d = np.array(training_image.get_fdata()[::, k, ::])\r\n",
        "            \r\n",
        "            image_2d_resized = resize(image_2d, (128,128), preserve_range=True)\r\n",
        "            mask_2d_resized = resize(mask_2d, (128,128), preserve_range=True)\r\n",
        "           \r\n",
        "            print(\"k=\"+str(k))\r\n",
        "           #array of chosen 2D images of all patients appended together \r\n",
        "           #(Array of 2D arrays)\r\n",
        "            masks_train.append(mask_2d_resized)\r\n",
        "            imgs_train.append(image_2d_resized)\r\n",
        "\r\n",
        "\r\n",
        "        for k in range((training_mask.shape[0]//2)-1,(training_mask.shape[0]//2)+1):\r\n",
        "            #axial cuts are made along the x axis\r\n",
        "            mask_2d = np.array(training_mask.get_fdata()[ k, ::, ::]) \r\n",
        "            image_2d = np.array(training_image.get_fdata()[k, ::, ::])\r\n",
        "            \r\n",
        "            image_2d_resized = resize(image_2d, (128,128), preserve_range=True)\r\n",
        "            mask_2d_resized = resize(mask_2d, (128,128), preserve_range=True)\r\n",
        "           \r\n",
        "            print(\"k=\"+str(k))\r\n",
        "           #array of chosen 2D images of all patients appended together \r\n",
        "           #(Array of 2D arrays)\r\n",
        "            masks_train.append(mask_2d_resized)\r\n",
        "            imgs_train.append(image_2d_resized)\r\n",
        "\r\n",
        "            \r\n",
        "   \r\n",
        "    #creating an empty numpy array \r\n",
        "        \r\n",
        "    imgs = np.ndarray((len(imgs_train), 128, 128), dtype=np.uint8)\r\n",
        "    imgs_mask = np.ndarray((len(masks_train), 128, 128), dtype=np.uint8)\r\n",
        "\r\n",
        "\r\n",
        "    # converting from list to numpy array\r\n",
        "    for index, img in enumerate(imgs_train):\r\n",
        "        imgs[index, :, :] = img\r\n",
        "    # converting from list to numpy array\r\n",
        "    for index, img in enumerate(masks_train):\r\n",
        "        imgs_mask[index, :, :] = img\r\n",
        "\r\n",
        "    #saving numpy array file   \r\n",
        "    np.save('/content/drive/MyDrive/numpy array files 2.5D/3 orthogonal planes//imgs_train.npy', imgs)\r\n",
        "    np.save('/content/drive/MyDrive/numpy array files 2.5D/3 orthogonal planes//masks_train.npy', imgs_mask)\r\n",
        "\r\n",
        "    print('Saving training data to .npy files done.')\r\n",
        "\r\n",
        "def create_test_data():\r\n",
        "    print('-'*30)\r\n",
        "    print('Creating test data...')\r\n",
        "    print('-'*30)\r\n",
        "    test_data_path = '//content//drive//MyDrive//test'\r\n",
        "\r\n",
        "    tt=os.path.join(test_data_path, 'test')\r\n",
        "    test_mask_path = os.path.join(test_data_path, 'mask')\r\n",
        "\r\n",
        "    imgs_test = os.listdir(tt)     \r\n",
        "    masks_test = os.listdir(test_mask_path) \r\n",
        "\r\n",
        "    #sorting file names alphabetically so they are correctly ordered  \r\n",
        "    list.sort(imgs_test)\r\n",
        "    list.sort(masks_test)\r\n",
        "\r\n",
        "     \r\n",
        "\r\n",
        "    #looping over names of 3D images and extracting 2D images from them\r\n",
        "    for i in range(len(imgs_test)):\r\n",
        "       # every patient has 3 mri modalities with only 1 mask \r\n",
        "        # so \"i\" is divided by 3 in masks_test[i//3] so the same mask \r\n",
        "        # is used for with its 3 corresponding mri scans\r\n",
        "\r\n",
        "        # we load 3D training masks\r\n",
        "        img = nibabel.load(os.path.join(tt,imgs_test[i]))\r\n",
        "        msk = nibabel.load(os.path.join(test_mask_path ,  masks_test[i//3]))\r\n",
        "       \r\n",
        "    #since we are doing 2.5D we will only use specific 2D images from the 3D image\r\n",
        "    #the chosen 2D images will be appended to the following two arrays:\r\n",
        "\r\n",
        "        imgs_testnpy=[]\r\n",
        "        masks_testnpy=[]\r\n",
        "          \r\n",
        "        # 3D image is converted to a 3D numpy array\r\n",
        "        # k is the index you  take the 2D image at.\r\n",
        "        # In this approach we took 3 consecutive 2D images from the center of the 3Dimage in 3 orthogonal planes\r\n",
        "        for k in range((img.shape[2]//2)-1,(img.shape[2]//2)+1):\r\n",
        "            #axial cuts are made along the z axis\r\n",
        "            img_2d = np.array(img.get_fdata()[::, ::, k])\r\n",
        "            msk_2d = np.array(msk.get_fdata()[::, ::, k])\r\n",
        "\r\n",
        "            img_2d_resized = resize(img_2d, (128,128), preserve_range=True)\r\n",
        "            msk_2d_resized = resize(msk_2d, (128,128), preserve_range=True)\r\n",
        "           \r\n",
        "            print(\"k=\"+str(k))\r\n",
        "           #array of chosen 2D images of all patients appended together \r\n",
        "           #(Array of 2D arrays)\r\n",
        "            imgs_testnpy.append(img_2d_resized)\r\n",
        "            masks_testnpy.append(msk_2d_resized)\r\n",
        "        for k in range((img.shape[1]//2)-1,(img.shape[1]//2)+1):\r\n",
        "       \r\n",
        "            #axial cuts are made along the y axis\r\n",
        "            img_2d = np.array(img.get_fdata()[::, k, ::])\r\n",
        "            msk_2d = np.array(msk.get_fdata()[::, k, ::])\r\n",
        "            \r\n",
        "            img_2d_resized = resize(img_2d, (128,128), preserve_range=True)\r\n",
        "            msk_2d_resized = resize(msk_2d, (128,128), preserve_range=True)\r\n",
        "           \r\n",
        "            print(\"k=\"+str(k))\r\n",
        "           #array of chosen 2D images of all patients appended together \r\n",
        "           #(Array of 2D arrays)\r\n",
        "            imgs_testnpy.append(img_2d_resized)\r\n",
        "            masks_testnpy.append(msk_2d_resized)\r\n",
        "\r\n",
        "        for k in range((img.shape[0]//2)-1,(img.shape[0]//2)+1):\r\n",
        "            #axial cuts are made along the x axis\r\n",
        "            img_2d = np.array(img.get_fdata()[k, ::, ::])\r\n",
        "            msk_2d = np.array(msk.get_fdata()[k, ::, ::])\r\n",
        "            \r\n",
        "            img_2d_resized = resize(img_2d, (128,128), preserve_range=True)\r\n",
        "            msk_2d_resized = resize(msk_2d, (128,128), preserve_range=True)\r\n",
        "           \r\n",
        "            print(\"k=\"+str(k))\r\n",
        "           #array of chosen 2D images of all patients appended together \r\n",
        "           #(Array of 2D arrays)\r\n",
        "            imgs_testnpy.append(img_2d_resized)\r\n",
        "            masks_testnpy.append(msk_2d_resized)\r\n",
        "\r\n",
        "      \r\n",
        "\r\n",
        "    # creating an empty numpy array \r\n",
        "    imgst = np.ndarray((len(imgs_testnpy), 128, 128), dtype=np.uint8)\r\n",
        "    imgs_maskt = np.ndarray((len(masks_testnpy), 128, 128), dtype=np.uint8)\r\n",
        "    \r\n",
        "    # converting from list to numpy array\r\n",
        "    for index, img in enumerate(imgs_testnpy):\r\n",
        "        imgst[index, :, :] = img\r\n",
        "        print(index)\r\n",
        "    \r\n",
        "    # converting from list to numpy array\r\n",
        "    for index, img in enumerate(masks_testnpy):\r\n",
        "        imgs_maskt[index, :, :] = img\r\n",
        "\r\n",
        "    #saving numpy array file   \r\n",
        "    np.save('/content/drive/MyDrive/numpy array files 2.5D/3 orthogonal planes/imgs_test.npy', imgst)\r\n",
        "    np.save('/content/drive/MyDrive/numpy array files 2.5D/3 orthogonal planes/masks_test.npy', imgs_maskt)\r\n",
        "\r\n",
        "    print('Saving test data to .npy files done.')\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    create_train_data()\r\n",
        "    create_test_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83Zv5UDBgGt7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "592612cb-69a5-4b21-e2af-35b6f9f534f9"
      },
      "source": [
        "from __future__ import print_function\r\n",
        "\r\n",
        "import os\r\n",
        "from skimage.transform import resize\r\n",
        "from skimage.io import imsave\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from skimage.segmentation import mark_boundaries\r\n",
        "from keras.models import Model\r\n",
        "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\r\n",
        "from keras.optimizers import Adam, SGD\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "from keras import backend as K\r\n",
        "from skimage.exposure import rescale_intensity\r\n",
        "from keras.callbacks import History\r\n",
        "from skimage import io\r\n",
        "from OPoad import load_train_data, load_test_data\r\n",
        "import nibabel as nib \r\n",
        "# powers of 2 are preferred in rows and cols so in down convolution we can split \r\n",
        "#the image dimensions by 2 several times without getting fractions\r\n",
        "image_rows=128\r\n",
        "image_cols=128\r\n",
        "smooth = 1.\r\n",
        "\r\n",
        "def dice_coef(y_true, y_pred):\r\n",
        "    y_true_f = K.flatten(y_true)\r\n",
        "    y_pred_f = K.flatten(y_pred)\r\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\r\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\r\n",
        "\r\n",
        "def dice_coef_loss(y_true, y_pred):\r\n",
        "    return -dice_coef(y_true, y_pred)\r\n",
        "\r\n",
        "def get_unet():\r\n",
        "    #down-convolution\r\n",
        "    inputs = Input((image_rows, image_cols, 1))\r\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\r\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\r\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\r\n",
        "    \r\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\r\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\r\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\r\n",
        "   \r\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\r\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\r\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\r\n",
        "    \r\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\r\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\r\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\r\n",
        "\r\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\r\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\r\n",
        "    \r\n",
        "    #up-convolution:\r\n",
        "    \r\n",
        "    up6 = concatenate([Conv2DTranspose(250, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\r\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\r\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\r\n",
        "\r\n",
        "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\r\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\r\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\r\n",
        "\r\n",
        "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\r\n",
        "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\r\n",
        "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\r\n",
        "\r\n",
        "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\r\n",
        "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\r\n",
        "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\r\n",
        "\r\n",
        "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\r\n",
        "\r\n",
        "    model = Model(inputs=[inputs], outputs=[conv10])\r\n",
        "\r\n",
        "    model.compile(optimizer=Adam(lr=1e-3), loss=dice_coef_loss, metrics=[dice_coef])\r\n",
        "\r\n",
        "    return model\r\n",
        "\r\n",
        "#The different layers in our neural network model (including convolutions, maxpooling and upsampling)\r\n",
        "\r\n",
        "def preprocess(imgs):\r\n",
        "  #We adapt here our dataset samples dimension to 128x128 so that we can feed it to our network\r\n",
        "    imgs_p = np.ndarray((imgs.shape[0], image_rows, image_cols), dtype=np.uint8)\r\n",
        "    for i in range(imgs.shape[0]):\r\n",
        "        imgs_p[i] = resize(imgs[i], (image_rows, image_cols), preserve_range=True)\r\n",
        "\r\n",
        "    imgs_p = imgs_p[..., np.newaxis]\r\n",
        "    return imgs_p\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "def train_and_predict():\r\n",
        "    print('-'*30)\r\n",
        "    print('Loading and preprocessing train data...')\r\n",
        "    print('-'*30)\r\n",
        "    \r\n",
        "    imgs_train, imgs_mask_train = load_train_data()\r\n",
        "\r\n",
        "    #imgs_train = preprocess(imgs_train)\r\n",
        "    #imgs_mask_train = preprocess(imgs_mask_train)\r\n",
        "\r\n",
        "    imgs_train = imgs_train.astype('float32')\r\n",
        "    mean = np.mean(imgs_train)  # mean for data centering\r\n",
        "    std = np.std(imgs_train)  # std for data normalization\r\n",
        "\r\n",
        "    imgs_train -= mean\r\n",
        "    imgs_train /= std\r\n",
        "    #Normalization of the train set\r\n",
        "\r\n",
        "    imgs_mask_train = imgs_mask_train.astype('float32')\r\n",
        "\r\n",
        "    print('-'*30)\r\n",
        "    print('Creating and compiling model...')\r\n",
        "    print('-'*30)\r\n",
        "    model = get_unet()\r\n",
        "    model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\r\n",
        "    #Saving the weights and the loss of the best predictions we obtained\r\n",
        "\r\n",
        "    print('-'*30)\r\n",
        "    print('Fitting model...')\r\n",
        "    print('-'*30)\r\n",
        "\r\n",
        "    history=model.fit(imgs_train, imgs_mask_train, batch_size=1, epochs=50, verbose=1, shuffle=True,\r\n",
        "              validation_split=0.5,callbacks=[model_checkpoint])\r\n",
        "\r\n",
        "    print('-'*30)\r\n",
        "    print('Loading and preprocessing test data...')\r\n",
        "    print('-'*30)\r\n",
        "\r\n",
        "    imgs_test, imgs_maskt = load_test_data()\r\n",
        "    \r\n",
        "    imgs_test = preprocess(imgs_test)\r\n",
        "\r\n",
        "    imgs_test = imgs_test.astype('float32')\r\n",
        "    imgs_test -= mean\r\n",
        "    imgs_test /= std\r\n",
        "    #Normalization of the test set\r\n",
        "\r\n",
        "    print('-'*30)\r\n",
        "    print('Loading saved weights...')\r\n",
        "    print('-'*30)\r\n",
        "    model.load_weights('weights.h5')\r\n",
        "\r\n",
        "    print('-'*30)\r\n",
        "    print('Predicting masks on test data...')\r\n",
        "    print('-'*30)\r\n",
        "    \r\n",
        "    pred_mask_test = model.predict(imgs_test, verbose=1)\r\n",
        "\r\n",
        "    np.save('pred_mask_test.npy', pred_mask_test)\r\n",
        "\r\n",
        "    print(type(pred_mask_test))\r\n",
        "\r\n",
        "    print('-' * 30)\r\n",
        "    print('Saving predicted masks to files...')\r\n",
        "    print('-' * 30)\r\n",
        "    pred_dir = '/content/drive/MyDrive/train'\r\n",
        "\r\n",
        "    #for k in range(len(pred_mask_test)):\r\n",
        "    #  a = rescale_intensity(imgs_test[k][:,:,0],out_range=(-1,1))\r\n",
        "    #  b = (pred_mask_test[k][:,:,0]).astype('uint8')\r\n",
        "    #  io.imsave(os.path.join(pred_dir, str(k) + '_pred.png'),mark_boundaries(a,b))\r\n",
        "\r\n",
        "    #Saving our predictions in the directory 'preds'\r\n",
        "    plt.plot(history.history['dice_coef'])\r\n",
        "    plt.plot(history.history['val_dice_coef'])\r\n",
        "    plt.title('Model dice coeff')\r\n",
        "    plt.ylabel('Dice coeff')\r\n",
        "    plt.xlabel('Epoch')\r\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\r\n",
        "    plt.show()\r\n",
        "    #plotting our dice coeff results in function of the number of epochs\r\n",
        "\r\n",
        " \r\n",
        "    results=model.evaluate(imgs_test,pred_mask_test,1)\r\n",
        "    print(\"test loss, test acc:\", results)\r\n",
        " \r\n",
        "if __name__ == '__main__':\r\n",
        "    train_and_predict()\r\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "Loading and preprocessing train data...\n",
            "------------------------------\n",
            "------------------------------\n",
            "Creating and compiling model...\n",
            "------------------------------\n",
            "------------------------------\n",
            "Fitting model...\n",
            "------------------------------\n",
            "Epoch 1/50\n",
            "336/336 [==============================] - 7s 17ms/step - loss: -0.4589 - dice_coef: 0.4589 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 2/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6719 - dice_coef: 0.6719 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 3/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6539 - dice_coef: 0.6539 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 4/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6391 - dice_coef: 0.6391 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 5/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6638 - dice_coef: 0.6638 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 6/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6525 - dice_coef: 0.6525 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 7/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6448 - dice_coef: 0.6448 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 8/50\n",
            "336/336 [==============================] - 5s 16ms/step - loss: -0.6403 - dice_coef: 0.6403 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 9/50\n",
            "336/336 [==============================] - 5s 16ms/step - loss: -0.6439 - dice_coef: 0.6439 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 10/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6250 - dice_coef: 0.6250 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 11/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6208 - dice_coef: 0.6208 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 12/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6757 - dice_coef: 0.6757 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 13/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6456 - dice_coef: 0.6456 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 14/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6532 - dice_coef: 0.6532 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 15/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6443 - dice_coef: 0.6443 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 16/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6562 - dice_coef: 0.6562 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 17/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6726 - dice_coef: 0.6726 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 18/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6659 - dice_coef: 0.6659 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 19/50\n",
            "336/336 [==============================] - 5s 16ms/step - loss: -0.6327 - dice_coef: 0.6327 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 20/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6772 - dice_coef: 0.6772 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 21/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6507 - dice_coef: 0.6507 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 22/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6287 - dice_coef: 0.6287 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 23/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6864 - dice_coef: 0.6864 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 24/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6408 - dice_coef: 0.6408 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 25/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6547 - dice_coef: 0.6547 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 26/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6688 - dice_coef: 0.6688 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 27/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6447 - dice_coef: 0.6447 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 28/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6593 - dice_coef: 0.6593 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 29/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6888 - dice_coef: 0.6888 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 30/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6333 - dice_coef: 0.6333 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 31/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6275 - dice_coef: 0.6275 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 32/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6176 - dice_coef: 0.6176 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 33/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6235 - dice_coef: 0.6235 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 34/50\n",
            "336/336 [==============================] - 5s 16ms/step - loss: -0.6243 - dice_coef: 0.6243 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 35/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6824 - dice_coef: 0.6824 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 36/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6911 - dice_coef: 0.6911 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 37/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6422 - dice_coef: 0.6422 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 38/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6601 - dice_coef: 0.6601 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 39/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6972 - dice_coef: 0.6972 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 40/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6963 - dice_coef: 0.6963 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 41/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6374 - dice_coef: 0.6374 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 42/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6460 - dice_coef: 0.6460 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 43/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6800 - dice_coef: 0.6800 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 44/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6405 - dice_coef: 0.6405 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 45/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6513 - dice_coef: 0.6513 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 46/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6258 - dice_coef: 0.6258 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 47/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6610 - dice_coef: 0.6610 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 48/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6460 - dice_coef: 0.6460 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 49/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.6557 - dice_coef: 0.6557 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "Epoch 50/50\n",
            "336/336 [==============================] - 5s 15ms/step - loss: -0.7151 - dice_coef: 0.7151 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
            "------------------------------\n",
            "Loading and preprocessing test data...\n",
            "------------------------------\n",
            "------------------------------\n",
            "Loading saved weights...\n",
            "------------------------------\n",
            "------------------------------\n",
            "Predicting masks on test data...\n",
            "------------------------------\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7480331ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 227ms/step\n",
            "<class 'numpy.ndarray'>\n",
            "------------------------------\n",
            "Saving predicted masks to files...\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 4ms/step - loss: -1.0000 - dice_coef: 1.0000\n",
            "test loss, test acc: [-1.0, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}