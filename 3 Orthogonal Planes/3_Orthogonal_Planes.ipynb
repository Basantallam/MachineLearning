{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3 Orthogonal Planes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1rhfQfyCndjmLdXRT-Rwq8XBXJfWCR3lX",
      "authorship_tag": "ABX9TyNGuE3416FnR01BtcEHg4az",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Basantallam/MachineLearning-Segmentation/blob/main/3_Orthogonal_Planes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHH-o2vefbvz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "552b750a-2f53-479f-f329-fbe7365fc2a0"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import nibabel\r\n",
        "from skimage.transform import resize\r\n",
        "\r\n",
        "data_path = '//content//drive//MyDrive'\r\n",
        "\r\n",
        "new_dimension=128\r\n",
        "\r\n",
        "def create_train_data():\r\n",
        "    print('-'*30)\r\n",
        "    print('Creating training data...')\r\n",
        "    print('-'*30)\r\n",
        "    #listing names of all training data into an array of strings\r\n",
        "    #1st array is for input and the 2nd for labels (masks)\r\n",
        "    train_data_path = os.path.join(data_path, 'train//train')\r\n",
        "    training_images = os.listdir(train_data_path)\r\n",
        "\r\n",
        "    train_mask_data_path = os.path.join(data_path, 'train//train_masks')\r\n",
        "    training_masks = os.listdir(train_mask_data_path)\r\n",
        "\r\n",
        "    #sorting file names alphabetically so they are correctly ordered  \r\n",
        "    list.sort(training_images)\r\n",
        "    list.sort(training_masks)\r\n",
        "\r\n",
        "    #since we are doing 2.5D we will only use specific 2D images from the 3D image\r\n",
        "    #the chosen 2D images will be appended to the following two arrays:\r\n",
        "\r\n",
        "    #training images\r\n",
        "    imgs_train = [] \r\n",
        "    #training masks \r\n",
        "    masks_train = [] \r\n",
        "\r\n",
        "    #looping over names of 3D images and extracting 2D images from them\r\n",
        "    for i in range(0,len(training_images)):\r\n",
        "      \r\n",
        "        # every patient has 4 mri modalities with only 1 mask \r\n",
        "        # so \"i\" is divided by 4 in training_masks[i//4] so the same mask \r\n",
        "        # is used for with its 4 corresponding mri scans\r\n",
        "        # we load 3D training masks\r\n",
        "        training_mask = nibabel.load(os.path.join(train_mask_data_path,training_masks[i//4]))\r\n",
        "        #we load 3D training image\r\n",
        "        training_image = nibabel.load(os.path.join(train_data_path, training_images[i])) \r\n",
        "        \r\n",
        "        #3D image is converted to a 3D numpy array\r\n",
        "        #k is the index you  take the 2D image at.\r\n",
        "        #In this approach we took 3 consecutive 2D images from the center of the 3Dimage in 3 orthogonal planes\r\n",
        "        for k in range((training_mask.shape[2]//2)-1,(training_mask.shape[2]//2)+1):\r\n",
        "            #axial cuts are made along the z axis\r\n",
        "            print(training_mask.get_fdata().shape)\r\n",
        "\r\n",
        "            mask_2d = np.array(training_mask.get_fdata()[::, ::, k]) \r\n",
        "            image_2d = np.array(training_image.get_fdata()[::, ::, k])\r\n",
        "            \r\n",
        "            image_2d_resized = resize(image_2d, (new_dimension,new_dimension), preserve_range=True)\r\n",
        "            mask_2d_resized = resize(mask_2d, (new_dimension,new_dimension), preserve_range=True)\r\n",
        "           \r\n",
        "            print(\"k=\"+str(k))\r\n",
        "           #array of chosen 2D images of all patients appended together \r\n",
        "           #(Array of 2D arrays)\r\n",
        "            masks_train.append(mask_2d_resized)\r\n",
        "            imgs_train.append(image_2d_resized)\r\n",
        "\r\n",
        "        for k in range((training_mask.shape[1]//2)-1,(training_mask.shape[1]//2)+1):\r\n",
        "            #axial cuts are made along the y axis\r\n",
        "            mask_2d = np.array(training_mask.get_fdata()[::, k, ::]) \r\n",
        "            image_2d = np.array(training_image.get_fdata()[::, k, ::])\r\n",
        "            \r\n",
        "            image_2d_resized = resize(image_2d, (new_dimension,new_dimension), preserve_range=True)\r\n",
        "            mask_2d_resized = resize(mask_2d, (new_dimension,new_dimension), preserve_range=True)\r\n",
        "           \r\n",
        "           # print(\"k=\"+str(k))\r\n",
        "           #array of chosen 2D images of all patients appended together \r\n",
        "           #(Array of 2D arrays)\r\n",
        "            masks_train.append(mask_2d_resized)\r\n",
        "            imgs_train.append(image_2d_resized)\r\n",
        "\r\n",
        "\r\n",
        "        for k in range((training_mask.shape[0]//2)-1,(training_mask.shape[0]//2)+1):\r\n",
        "            #axial cuts are made along the x axis\r\n",
        "            mask_2d = np.array(training_mask.get_fdata()[ k, ::, ::]) \r\n",
        "            image_2d = np.array(training_image.get_fdata()[k, ::, ::])\r\n",
        "            \r\n",
        "            image_2d_resized = resize(image_2d, (new_dimension,new_dimension), preserve_range=True)\r\n",
        "            mask_2d_resized = resize(mask_2d, (new_dimension,new_dimension), preserve_range=True)\r\n",
        "           \r\n",
        "            print(\"k=\"+str(k))\r\n",
        "           #array of chosen 2D images of all patients appended together \r\n",
        "           #(Array of 2D arrays)\r\n",
        "            masks_train.append(mask_2d_resized)\r\n",
        "            imgs_train.append(image_2d_resized)\r\n",
        "\r\n",
        "            \r\n",
        "   \r\n",
        "    #creating an empty numpy array \r\n",
        "        \r\n",
        "    imgs = np.ndarray((len(imgs_train), new_dimension, new_dimension), dtype=np.uint8)\r\n",
        "    imgs_mask = np.ndarray((len(masks_train), new_dimension, new_dimension), dtype=np.uint8)\r\n",
        "\r\n",
        "\r\n",
        "    # converting from list to numpy array\r\n",
        "    for index, img in enumerate(imgs_train):\r\n",
        "        imgs[index, :, :] = img\r\n",
        "    # converting from list to numpy array\r\n",
        "    for index, img in enumerate(masks_train):\r\n",
        "        imgs_mask[index, :, :] = img\r\n",
        "\r\n",
        "    #saving numpy array file   \r\n",
        "    np.save('/content/drive/MyDrive/numpy array files 2.5D/3 orthogonal planes//128/imgs_train.npy', imgs)\r\n",
        "    np.save('/content/drive/MyDrive/numpy array files 2.5D/3 orthogonal planes//128/masks_train.npy', imgs_mask)\r\n",
        "\r\n",
        "    print('Saving training data to .npy files done.')\r\n",
        "\r\n",
        "def create_test_data():\r\n",
        "    print('-'*30)\r\n",
        "    print('Creating test data...')\r\n",
        "    print('-'*30)\r\n",
        "    test_data_path = '//content//drive//MyDrive//test'\r\n",
        "\r\n",
        "    tt=os.path.join(test_data_path, 'test')\r\n",
        "    test_mask_path = os.path.join(test_data_path, 'mask')\r\n",
        "\r\n",
        "    imgs_test = os.listdir(tt)     \r\n",
        "    masks_test = os.listdir(test_mask_path) \r\n",
        "\r\n",
        "    #sorting file names alphabetically so they are correctly ordered  \r\n",
        "    list.sort(imgs_test)\r\n",
        "    list.sort(masks_test)\r\n",
        "\r\n",
        "     \r\n",
        "\r\n",
        "    #looping over names of 3D images and extracting 2D images from them\r\n",
        "    for i in range(0,len(imgs_test)):\r\n",
        "      \r\n",
        "       # every patient has 3 mri modalities with only 1 mask \r\n",
        "        # so \"i\" is divided by 3 in masks_test[i//3] so the same mask \r\n",
        "        # is used for with its 3 corresponding mri scans\r\n",
        "\r\n",
        "        # we load 3D training masks\r\n",
        "        img = nibabel.load(os.path.join(tt,imgs_test[i]))\r\n",
        "        msk = nibabel.load(os.path.join(test_mask_path ,  masks_test[i//3]))\r\n",
        "       \r\n",
        "    #since we are doing 2.5D we will only use specific 2D images from the 3D image\r\n",
        "    #the chosen 2D images will be appended to the following two arrays:\r\n",
        "\r\n",
        "        imgs_testnpy=[]\r\n",
        "        masks_testnpy=[]\r\n",
        "          \r\n",
        "        # 3D image is converted to a 3D numpy array\r\n",
        "        # k is the index you  take the 2D image at.\r\n",
        "        # In this approach we took 3 consecutive 2D images from the center of the 3Dimage in 3 orthogonal planes\r\n",
        "        for k in range((img.shape[2]//2)-1,(img.shape[2]//2)+1):\r\n",
        "            #axial cuts are made along the z axis\r\n",
        "            img_2d = np.array(img.get_fdata()[::, ::, k])\r\n",
        "            msk_2d = np.array(msk.get_fdata()[::, ::, k])\r\n",
        "\r\n",
        "            img_2d_resized = resize(img_2d, (new_dimension,new_dimension), preserve_range=True)\r\n",
        "            msk_2d_resized = resize(msk_2d, (new_dimension,new_dimension), preserve_range=True)\r\n",
        "           \r\n",
        "            print(\"k=\"+str(k))\r\n",
        "           #array of chosen 2D images of all patients appended together \r\n",
        "           #(Array of 2D arrays)\r\n",
        "            imgs_testnpy.append(img_2d_resized)\r\n",
        "            masks_testnpy.append(msk_2d_resized)\r\n",
        "        for k in range((img.shape[1]//2)-1,(img.shape[1]//2)+1):\r\n",
        "       \r\n",
        "            #axial cuts are made along the y axis\r\n",
        "            img_2d = np.array(img.get_fdata()[::, k, ::])\r\n",
        "            msk_2d = np.array(msk.get_fdata()[::, k, ::])\r\n",
        "            \r\n",
        "            img_2d_resized = resize(img_2d, (new_dimension,new_dimension), preserve_range=True)\r\n",
        "            msk_2d_resized = resize(msk_2d, (new_dimension,new_dimension), preserve_range=True)\r\n",
        "           \r\n",
        "            #print(\"k=\"+str(k))\r\n",
        "           #array of chosen 2D images of all patients appended together \r\n",
        "           #(Array of 2D arrays)\r\n",
        "            imgs_testnpy.append(img_2d_resized)\r\n",
        "            masks_testnpy.append(msk_2d_resized)\r\n",
        "\r\n",
        "        for k in range((img.shape[0]//2)-1,(img.shape[0]//2)+1):\r\n",
        "            #axial cuts are made along the x axis\r\n",
        "            img_2d = np.array(img.get_fdata()[k, ::, ::])\r\n",
        "            msk_2d = np.array(msk.get_fdata()[k, ::, ::])\r\n",
        "            \r\n",
        "            img_2d_resized = resize(img_2d, (new_dimension,new_dimension), preserve_range=True)\r\n",
        "            msk_2d_resized = resize(msk_2d, (new_dimension,new_dimension), preserve_range=True)\r\n",
        "           \r\n",
        "            #print(\"k=\"+str(k))\r\n",
        "           #array of chosen 2D images of all patients appended together \r\n",
        "           #(Array of 2D arrays)\r\n",
        "            imgs_testnpy.append(img_2d_resized)\r\n",
        "            masks_testnpy.append(msk_2d_resized)\r\n",
        "\r\n",
        "      \r\n",
        "\r\n",
        "    # creating an empty numpy array \r\n",
        "    imgst = np.ndarray((len(imgs_testnpy), new_dimension, new_dimension), dtype=np.uint8)\r\n",
        "    imgs_maskt = np.ndarray((len(masks_testnpy), new_dimension, new_dimension), dtype=np.uint8)\r\n",
        "    \r\n",
        "    # converting from list to numpy array\r\n",
        "    for index, img in enumerate(imgs_testnpy):\r\n",
        "        imgst[index, :, :] = img\r\n",
        "        print(index)\r\n",
        "    \r\n",
        "    # converting from list to numpy array\r\n",
        "    for index, img in enumerate(masks_testnpy):\r\n",
        "        imgs_maskt[index, :, :] = img\r\n",
        "\r\n",
        "    #saving numpy array file   \r\n",
        "    np.save('/content/drive/MyDrive/numpy array files 2.5D/3 orthogonal planes/128/imgs_test.npy', imgst)\r\n",
        "    np.save('/content/drive/MyDrive/numpy array files 2.5D/3 orthogonal planes/128/masks_test.npy', imgs_maskt)\r\n",
        "\r\n",
        "    print('Saving test data to .npy files done.')\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    create_train_data()\r\n",
        "    create_test_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "Creating training data...\n",
            "------------------------------\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "(181, 217, 181)\n",
            "k=89\n",
            "(181, 217, 181)\n",
            "k=90\n",
            "k=107\n",
            "k=108\n",
            "k=89\n",
            "k=90\n",
            "Saving training data to .npy files done.\n",
            "------------------------------\n",
            "Creating test data...\n",
            "------------------------------\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "k=89\n",
            "k=90\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "Saving test data to .npy files done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83Zv5UDBgGt7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd15773a-bf28-4f01-e628-bea1bf7977ca"
      },
      "source": [
        "from __future__ import print_function\r\n",
        "\r\n",
        "import os\r\n",
        "from skimage.transform import resize\r\n",
        "from skimage.io import imsave\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from skimage.segmentation import mark_boundaries\r\n",
        "from keras.models import Model\r\n",
        "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\r\n",
        "from keras.optimizers import Adam, SGD\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "from keras import backend as K\r\n",
        "from skimage.exposure import rescale_intensity\r\n",
        "from keras.callbacks import History\r\n",
        "from skimage import io\r\n",
        "from OPoad128 import load_train_data, load_test_data\r\n",
        "import nibabel as nib \r\n",
        "# powers of 2 are preferred in rows and cols so in down convolution we can split \r\n",
        "#the image dimensions by 2 several times without getting fractions\r\n",
        "image_rows=128\r\n",
        "image_cols=128\r\n",
        "smooth = 1.\r\n",
        "\r\n",
        "def dice_coef(y_true, y_pred):\r\n",
        "    y_true_f = K.flatten(y_true)\r\n",
        "    y_pred_f = K.flatten(y_pred)\r\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\r\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\r\n",
        "\r\n",
        "def dice_coef_loss(y_true, y_pred):\r\n",
        "    return -dice_coef(y_true, y_pred)\r\n",
        "\r\n",
        "def get_unet():\r\n",
        "    #down-convolution\r\n",
        "    inputs = Input((image_rows, image_cols, 1))\r\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\r\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\r\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\r\n",
        "    \r\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\r\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\r\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\r\n",
        "   \r\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\r\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\r\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\r\n",
        "    \r\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\r\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\r\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\r\n",
        "\r\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\r\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\r\n",
        "    \r\n",
        "    #up-convolution:\r\n",
        "    \r\n",
        "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\r\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\r\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\r\n",
        "\r\n",
        "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\r\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\r\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\r\n",
        "\r\n",
        "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\r\n",
        "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\r\n",
        "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\r\n",
        "\r\n",
        "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\r\n",
        "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\r\n",
        "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\r\n",
        "\r\n",
        "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\r\n",
        "\r\n",
        "    model = Model(inputs=[inputs], outputs=[conv10])\r\n",
        "\r\n",
        "    model.compile(optimizer=Adam(lr=1e-3), loss=dice_coef_loss, metrics=[dice_coef])\r\n",
        "\r\n",
        "    return model\r\n",
        "\r\n",
        "#The different layers in our neural network model (including convolutions, maxpooling and upsampling)\r\n",
        "\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "def train_and_predict():\r\n",
        "    print('-'*30)\r\n",
        "    print('Loading train data...')\r\n",
        "    print('-'*30)\r\n",
        "    \r\n",
        "    imgs_train, imgs_mask_train = load_train_data()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    imgs_train = imgs_train.astype('float32')\r\n",
        "    mean = np.mean(imgs_train)  # mean for data centering\r\n",
        "    std = np.std(imgs_train)  # std for data normalization\r\n",
        "\r\n",
        "    imgs_train -= mean\r\n",
        "    imgs_train /= std\r\n",
        "    #Normalization of the train set\r\n",
        "\r\n",
        "    imgs_mask_train = imgs_mask_train.astype('float32')\r\n",
        "\r\n",
        "    print('-'*30)\r\n",
        "    print('Creating and compiling model...')\r\n",
        "    print('-'*30)\r\n",
        "    model = get_unet()\r\n",
        "    model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\r\n",
        "    #Saving the weights and the loss of the best predictions we obtained\r\n",
        "\r\n",
        "    print('-'*30)\r\n",
        "    print('Fitting model...')\r\n",
        "    print('-'*30)\r\n",
        "\r\n",
        "    history=model.fit(imgs_train, imgs_mask_train, batch_size=1, epochs=50, verbose=1, shuffle=True,\r\n",
        "              validation_split=0.5,callbacks=[model_checkpoint])\r\n",
        "\r\n",
        "    print('-'*30)\r\n",
        "    print('Loading  test data...')\r\n",
        "    print('-'*30)\r\n",
        "\r\n",
        "    imgs_test, imgs_maskt = load_test_data()\r\n",
        "    \r\n",
        "    imgs_test = imgs_test.astype('float32')\r\n",
        "    imgs_test -= mean\r\n",
        "    imgs_test /= std\r\n",
        "    #Normalization of the test set\r\n",
        "\r\n",
        "    print('-'*30)\r\n",
        "    print('Loading saved weights...')\r\n",
        "    print('-'*30)\r\n",
        "    model.load_weights('weights.h5')\r\n",
        "\r\n",
        "    print('-'*30)\r\n",
        "    print('Predicting masks on test data...')\r\n",
        "    print('-'*30)\r\n",
        "    \r\n",
        "    pred_mask_test = model.predict(imgs_test, verbose=1)\r\n",
        "\r\n",
        "    np.save('pred_mask_test.npy', pred_mask_test)\r\n",
        "\r\n",
        "    print(type(pred_mask_test))\r\n",
        "\r\n",
        "    print('-' * 30)\r\n",
        "    print('Saving predicted masks to files...')\r\n",
        "    print('-' * 30)\r\n",
        "    pred_dir = '/content/drive/MyDrive/train'\r\n",
        "\r\n",
        "    #for k in range(len(pred_mask_test)):\r\n",
        "    #  a = rescale_intensity(imgs_test[k][:,:,0],out_range=(-1,1))\r\n",
        "    #  b = (pred_mask_test[k][:,:,0]).astype('uint8')\r\n",
        "    #  io.imsave(os.path.join(pred_dir, str(k) + '_pred.png'),mark_boundaries(a,b))\r\n",
        "\r\n",
        "    #Saving our predictions in the directory 'preds'\r\n",
        "    plt.plot(history.history['dice_coef'])\r\n",
        "    plt.plot(history.history['val_dice_coef'])\r\n",
        "    plt.title('Model dice coeff')\r\n",
        "    plt.ylabel('Dice coeff')\r\n",
        "    plt.xlabel('Epoch')\r\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\r\n",
        "    plt.show()\r\n",
        "    #plotting our dice coeff results in function of the number of epochs\r\n",
        "\r\n",
        " \r\n",
        "    results=model.evaluate(imgs_test,pred_mask_test,1)\r\n",
        "    print(\"test loss, test acc:\", results)\r\n",
        " \r\n",
        "if __name__ == '__main__':\r\n",
        "    train_and_predict()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "Loading train data...\n",
            "------------------------------\n",
            "------------------------------\n",
            "Creating and compiling model...\n",
            "------------------------------\n",
            "------------------------------\n",
            "Fitting model...\n",
            "------------------------------\n",
            "Epoch 1/50\n",
            "360/360 [==============================] - 8s 17ms/step - loss: -0.4308 - dice_coef: 0.4308 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 2/50\n",
            "360/360 [==============================] - 6s 17ms/step - loss: -0.6617 - dice_coef: 0.6617 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 3/50\n",
            "360/360 [==============================] - 6s 16ms/step - loss: -0.6482 - dice_coef: 0.6482 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 4/50\n",
            "360/360 [==============================] - 6s 16ms/step - loss: -0.6671 - dice_coef: 0.6671 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 5/50\n",
            "360/360 [==============================] - 6s 16ms/step - loss: -0.6490 - dice_coef: 0.6490 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 6/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6294 - dice_coef: 0.6294 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 7/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6314 - dice_coef: 0.6314 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 8/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6562 - dice_coef: 0.6562 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 9/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6207 - dice_coef: 0.6207 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 10/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6648 - dice_coef: 0.6648 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 11/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6514 - dice_coef: 0.6514 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 12/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6818 - dice_coef: 0.6818 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 13/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6398 - dice_coef: 0.6398 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 14/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6716 - dice_coef: 0.6716 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 15/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6358 - dice_coef: 0.6358 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 16/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6500 - dice_coef: 0.6500 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 17/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6405 - dice_coef: 0.6405 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 18/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6427 - dice_coef: 0.6427 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 19/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6901 - dice_coef: 0.6901 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 20/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6318 - dice_coef: 0.6318 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 21/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6325 - dice_coef: 0.6325 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 22/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6699 - dice_coef: 0.6699 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 23/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6826 - dice_coef: 0.6826 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 24/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6520 - dice_coef: 0.6520 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 25/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6636 - dice_coef: 0.6636 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 26/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6730 - dice_coef: 0.6730 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 27/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6618 - dice_coef: 0.6618 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 28/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6523 - dice_coef: 0.6523 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 29/50\n",
            "360/360 [==============================] - 6s 15ms/step - loss: -0.6836 - dice_coef: 0.6836 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 30/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6690 - dice_coef: 0.6690 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 31/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6658 - dice_coef: 0.6658 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 32/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6262 - dice_coef: 0.6262 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 33/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6499 - dice_coef: 0.6499 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 34/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6612 - dice_coef: 0.6612 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 35/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6324 - dice_coef: 0.6324 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 36/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6929 - dice_coef: 0.6929 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 37/50\n",
            "360/360 [==============================] - 6s 15ms/step - loss: -0.6422 - dice_coef: 0.6422 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 38/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6478 - dice_coef: 0.6478 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 39/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6678 - dice_coef: 0.6678 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 40/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6761 - dice_coef: 0.6761 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 41/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6374 - dice_coef: 0.6374 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 42/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6266 - dice_coef: 0.6266 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 43/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6451 - dice_coef: 0.6451 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 44/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6878 - dice_coef: 0.6878 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 45/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6413 - dice_coef: 0.6413 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 46/50\n",
            "360/360 [==============================] - 6s 15ms/step - loss: -0.6547 - dice_coef: 0.6547 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 47/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6693 - dice_coef: 0.6693 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 48/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6614 - dice_coef: 0.6614 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 49/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6502 - dice_coef: 0.6502 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "Epoch 50/50\n",
            "360/360 [==============================] - 5s 15ms/step - loss: -0.6844 - dice_coef: 0.6844 - val_loss: -0.7966 - val_dice_coef: 0.7966\n",
            "------------------------------\n",
            "Loading  test data...\n",
            "------------------------------\n",
            "------------------------------\n",
            "Loading saved weights...\n",
            "------------------------------\n",
            "------------------------------\n",
            "Predicting masks on test data...\n",
            "------------------------------\n",
            "1/1 [==============================] - 1s 547ms/step\n",
            "<class 'numpy.ndarray'>\n",
            "------------------------------\n",
            "Saving predicted masks to files...\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 4ms/step - loss: -1.0000 - dice_coef: 1.0000\n",
            "test loss, test acc: [-1.0, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
